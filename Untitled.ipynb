{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceaaa12e-9efa-4998-8ebf-9f9a393f7a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb51746-2dbf-4d16-8c3f-07bccd4152fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script strip-hints is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts dsl-compile, dsl-compile-v2 and kfp are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~hapely'.\n",
      "You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pygeos as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~eopandas'.\n",
      "You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install -q {USER_FLAG} google-cloud-aiplatform==1.59.0\n",
    "!pip3 install  -q {USER_FLAG} kfp google-cloud-pipeline-components==0.1.1 --upgrade\n",
    "!pip3 uninstall -q -y shapely pygeos geopandas\n",
    "!pip3 install -q shapely==1.8.5.post1 pygeos==0.12.0 geopandas>=0.12.2\n",
    "!pip3 install -q google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3029d28-35d3-4677-a503-e4b561d8d5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeadcc3-15fb-43dd-b917-7d8c822358be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87430492-8fe1-45a7-a354-a63f8202dca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1274a441-f2c1-4e28-9c5a-aa3295bf1a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d7677a-d91d-44ec-b590-38c690f93a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99c8e2b-704d-4358-adc7-e759f8903806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://qwiklabs-gcp-03-6a4399c9e9a3-bucket/pipeline_root/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793b69df-1f6d-41d2-942c-ab4394b1c7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", output_component_file=\"first-component.yaml\")\n",
    "def product_name(text: str) -> str:\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b145af-5c77-41cb-af6b-9fb88fc9318b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_name_component = kfp.components.load_component_from_file('./first-component.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c90bd4e-891c-4efd-a0a7-03878b499043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", output_component_file=\"second-component.yaml\", packages_to_install=[\"emoji\"])\n",
    "def emoji(\n",
    "    text: str,\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"emoji_text\", str),  # Return parameters\n",
    "        (\"emoji\", str),\n",
    "    ],\n",
    "):\n",
    "    import emoji\n",
    "\n",
    "    emoji_text = text\n",
    "    emoji_str = emoji.emojize(':' + emoji_text + ':', language='alias')\n",
    "    print(\"output one: {}; output_two: {}\".format(emoji_text, emoji_str))\n",
    "    return (emoji_text, emoji_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d1c19f-5de5-42aa-b459-740e71508cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", output_component_file=\"third-component.yaml\")\n",
    "def build_sentence(\n",
    "    product: str,\n",
    "    emoji: str,\n",
    "    emojitext: str\n",
    ") -> str:\n",
    "    print(\"We completed the pipeline, hooray!\")\n",
    "    end_str = product + \" is \"\n",
    "    if len(emoji) > 0:\n",
    "        end_str += emoji\n",
    "    else:\n",
    "        end_str += emojitext\n",
    "    return(end_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76058b76-fc9a-4bcb-b01c-6ef6eb4ad1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"hello-world\",\n",
    "    description=\"An intro pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def intro_pipeline(text: str = \"Vertex Pipelines\", emoji_str: str = \"sparkles\"):\n",
    "    product_task = product_name(text)\n",
    "    emoji_task = emoji(emoji_str)\n",
    "    consumer_task = build_sentence(\n",
    "        product_task.output,\n",
    "        emoji_task.outputs[\"emoji\"],\n",
    "        emoji_task.outputs[\"emoji_text\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "096f6456-8a14-4dde-b741-6d41fe1117b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"hello-world\",\n",
    "    description=\"An intro pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def intro_pipeline(text: str = \"Vertex Pipelines\", emoji_str: str = \"sparkles\"):\n",
    "    product_task = product_name(text)\n",
    "    emoji_task = emoji(emoji_str)\n",
    "    consumer_task = build_sentence(\n",
    "        product_task.output,\n",
    "        emoji_task.outputs[\"emoji\"],\n",
    "        emoji_task.outputs[\"emoji_text\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245af385-ec72-4f1b-b1c3-a605d0ff51ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/v2/compiler/compiler.py:1290: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=intro_pipeline, package_path=\"intro_pipeline_job.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592592ed-cd1e-4392-90c4-803f92ca52b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/kfp/v2/google/client/client.py:169: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f6e9ed3-84eb-4b8d-b0eb-cac047a32228",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9\", output_component_file=\"second-component.yaml\", packages_to_install=[\"emoji\"])\n",
    "def emoji(\n",
    "    text: str,\n",
    ") -> NamedTuple(\n",
    "    \"Outputs\",\n",
    "    [\n",
    "        (\"emoji_text\", str),  # Return parameters\n",
    "        (\"emoji\", str),\n",
    "    ],\n",
    "):\n",
    "    import emoji\n",
    "\n",
    "    emoji_text = text\n",
    "    emoji_str = emoji.emojize(':' + emoji_text + ':', language='alias')\n",
    "    print(\"output one: {}; output_two: {}\".format(emoji_text, emoji_str))\n",
    "    return (emoji_text, emoji_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d29a703-fbb8-4ec2-ab5e-6fbf356ed9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/hello-world-20241207153235?project=qwiklabs-gcp-03-6a4399c9e9a3\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"intro_pipeline_job.json\",\n",
    "    # pipeline_root=PIPELINE_ROOT  # this argument is necessary if you did not specify PIPELINE_ROOT as part of the pipeline definition.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fd7c9c1-fc1e-4be5-8423-5b1710b4aa95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 1: A custom component for model evaluation\n",
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"tables_eval_component.yaml\", # Optional: you can use this to load the component later\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classif_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,  # \"region\",\n",
    "    api_endpoint: str,  # \"region-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "\n",
    "    \"\"\"This function renders evaluation metrics for an AutoML Tabular classification model.\n",
    "    It retrieves the classification model evaluation generated by the AutoML Tabular training\n",
    "    process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n",
    "    for the model. It also uses given metrics threshold information and compares that to the\n",
    "    evaluation results to determine whether the model is sufficiently accurate to deploy.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is\n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\n",
    "                        \"{} < {}; returning False\".format(metrics_dict[k], v)\n",
    "                    )\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "150ee012-eafa-4421-9f5c-02344442ce10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-beans1733585701\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DISPLAY_NAME = 'automl-beans{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddf2e0c-af66-4083-bf24-ddc5e021f3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-tab-beans-training-v2\",\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    project: str = PROJECT_ID,\n",
    "    gcp_region: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "):\n",
    "    dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "        project=project, display_name=display_name, bq_source=bq_source\n",
    "    )\n",
    "\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        budget_milli_node_hours=1000,\n",
    "        column_transformations=[\n",
    "            {\"numeric\": {\"column_name\": \"Area\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Perimeter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MajorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MinorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"AspectRation\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Eccentricity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ConvexArea\"}},\n",
    "            {\"numeric\": {\"column_name\": \"EquivDiameter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Extent\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Solidity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"roundness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Compactness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor1\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor2\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor3\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor4\"}},\n",
    "            {\"categorical\": {\"column_name\": \"Class\"}},\n",
    "        ],\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "        target_column=\"Class\",\n",
    "    )\n",
    "    model_eval_task = classif_model_eval_metrics(\n",
    "        project,\n",
    "        gcp_region,\n",
    "        api_endpoint,\n",
    "        thresholds_dict_str,\n",
    "        training_op.outputs[\"model\"],\n",
    "    )\n",
    "\n",
    "    with dsl.Condition(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "\n",
    "        deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            model=training_op.outputs[\"model\"],\n",
    "            project=project,\n",
    "            machine_type=\"e2-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "713b755b-309c-44ef-aba9-80005cfaddd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tab_classif_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55afc199-c689-46f6-81b1-3b14853779a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/automl-tab-beans-training-v2-20241207153504?project=qwiklabs-gcp-03-6a4399c9e9a3\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    \"tab_classif_pipeline.json\", pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"project\": PROJECT_ID,\"display_name\": DISPLAY_NAME}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "231869d8-bc01-445a-a6e8-bb1ac0ca1bca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:thresholds_dict_str</th>\n",
       "      <th>param.input:project</th>\n",
       "      <th>param.input:display_name</th>\n",
       "      <th>param.input:api_endpoint</th>\n",
       "      <th>param.input:bq_source</th>\n",
       "      <th>param.input:gcp_region</th>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automl-tab-beans-training-v2</td>\n",
       "      <td>automl-tab-beans-training-v2-20241207153504</td>\n",
       "      <td>{\"auRoc\": 0.95}</td>\n",
       "      <td>qwiklabs-gcp-03-6a4399c9e9a3</td>\n",
       "      <td>automl-beans1733585701</td>\n",
       "      <td>us-central1-aiplatform.googleapis.com</td>\n",
       "      <td>bq://aju-dev-demos.beans.beans1</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pipeline_name                                     run_name  \\\n",
       "0  automl-tab-beans-training-v2  automl-tab-beans-training-v2-20241207153504   \n",
       "\n",
       "  param.input:thresholds_dict_str           param.input:project  \\\n",
       "0                 {\"auRoc\": 0.95}  qwiklabs-gcp-03-6a4399c9e9a3   \n",
       "\n",
       "  param.input:display_name               param.input:api_endpoint  \\\n",
       "0   automl-beans1733585701  us-central1-aiplatform.googleapis.com   \n",
       "\n",
       "             param.input:bq_source param.input:gcp_region  \\\n",
       "0  bq://aju-dev-demos.beans.beans1            us-central1   \n",
       "\n",
       "                     param.vmlmd_lineage_integration  \n",
       "0  {'pipeline_run_component': {'parent_task_names...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 4: Comparing metrics across pipeline runs (Optional)\n",
    "\n",
    "pipeline_df = aiplatform.get_pipeline_df(pipeline=\"automl-tab-beans-training-v2\")\n",
    "small_pipeline_df = pipeline_df.head(2)\n",
    "small_pipeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28186010-7d40-4ec4-a203-22871c79c0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
